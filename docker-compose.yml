services:
  whisper:
    build: 
      context: .
      dockerfile: Dockerfile.gpu
    command: [
      "uv", "run", "wyoming-faster-whisper",
      "--model", "base",
      "--uri", "tcp://0.0.0.0:10300",
      "--data-dir", "/data",
      "--beam-size", "5",
      "--language", "en",
      "--device", "cuda"
    ]
    volumes:
      - ./whisper-data:/data
    environment:
      # - TZ=Asia/Kolkata
      - local_files_only=False
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    ports:
      - 10300:10300